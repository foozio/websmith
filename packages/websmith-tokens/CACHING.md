# Token Generation Caching

This document describes the caching strategies implemented for token generation in the Websmith Kit.

## Overview

The caching system uses an LRU (Least Recently Used) cache to store the results of expensive token generation operations. This significantly improves performance for applications that generate tokens dynamically or frequently rebuild themes.

## Features

### LRU Cache Implementation
- **Configurable Size**: Set maximum number of cached entries per token type
- **TTL (Time To Live)**: Automatic expiration of stale entries
- **Eviction Strategy**: Automatically removes least recently used entries when cache is full
- **Enable/Disable**: Can be toggled on/off at runtime

### Cache Statistics
- **Hit Rate**: Percentage of cache hits vs total requests
- **Hits/Misses**: Track successful and unsuccessful cache lookups
- **Evictions**: Count of entries removed due to size limits
- **Size Tracking**: Current and maximum cache sizes

### Performance Monitoring Integration
- Cache statistics are integrated with the existing performance monitoring system
- Available in `tokenPerformanceMonitor.logSummary()` output
- Included in JSON exports via `tokenPerformanceMonitor.exportJSON()`

## Usage

### Basic Usage

```typescript
import { 
  generatePalette, 
  generateTypographyScale, 
  generateSpacingScale 
} from '@websmith/tokens'

// First call - cache miss, generates tokens
const palette1 = generatePalette({ h: 210, s: 60, l: 50 })

// Second call with same params - cache hit, returns cached result
const palette2 = generatePalette({ h: 210, s: 60, l: 50 })

// palette1 === palette2 (same reference)
```

### Cache Management

```typescript
import { 
  colorCache, 
  typographyCache, 
  spacingCache,
  getAllCacheStats,
  clearAllCaches,
  pruneAllCaches
} from '@websmith/tokens'

// Get statistics for all caches
const stats = getAllCacheStats()
console.log(stats.color.hitRate) // e.g., 0.75 (75% hit rate)

// Clear all caches
clearAllCaches()

// Remove expired entries
const pruned = pruneAllCaches()
console.log(`Removed ${pruned} expired entries`)

// Enable/disable individual caches
colorCache.setEnabled(false)
typographyCache.setEnabled(true)
```

### Custom Cache Configuration

```typescript
import { TokenCache } from '@websmith/tokens'

// Create a custom cache instance
const myCache = new TokenCache({
  maxSize: 50,           // Maximum 50 entries
  ttl: 1000 * 60 * 5,   // 5 minute TTL
  enabled: true          // Enabled by default
})

// Use the cache
myCache.set({ key: 'value' }, 'result')
const result = myCache.get({ key: 'value' })
```

## Cache Configuration

### Default Settings

| Cache Type | Max Size | TTL | Enabled |
|------------|----------|-----|---------|
| Color | 200 | 10 min | Yes* |
| Typography | 100 | 10 min | Yes* |
| Spacing | 50 | 10 min | Yes* |

*Disabled in test environment unless `WEBSMITH_CACHE=true`

### Environment Variables

- `NODE_ENV=test` - Disables caches by default in test environment
- `WEBSMITH_CACHE=true` - Force enable caches in test environment

## Performance Impact

### Benchmarks

Typical performance improvements with caching enabled:

- **Color Palette Generation**: ~95% faster for cached results
- **Typography Scale**: ~90% faster for cached results
- **Spacing Scale**: ~85% faster for cached results

### Memory Usage

- Each cache entry stores the input parameters and generated result
- Average memory per entry: ~1-5 KB depending on token complexity
- Total memory overhead with default settings: ~5-15 MB

## Implementation Details

### Cache Key Generation

Cache keys are generated by:
1. Serializing input parameters to JSON
2. Sorting object keys for consistency
3. Using the resulting string as the cache key

This ensures that `{ a: 1, b: 2 }` and `{ b: 2, a: 1 }` produce the same cache key.

### LRU Eviction

When the cache reaches maximum size:
1. The oldest (least recently accessed) entry is removed
2. New entry is added
3. Eviction counter is incremented

### TTL Expiration

Entries are checked for expiration on:
- Every `get()` operation
- Manual `prune()` calls

Expired entries are automatically removed and counted as cache misses.

## Testing

Comprehensive test coverage includes:
- Basic cache operations (get, set, has, clear)
- LRU eviction behavior
- TTL expiration
- Statistics tracking
- Enable/disable functionality
- Integration with token generators

Run tests:
```bash
npm run test -- packages/websmith-tokens/src/__tests__/cache.test.ts
```

## Best Practices

1. **Enable in Production**: Caching provides significant performance benefits
2. **Monitor Hit Rates**: Use `getAllCacheStats()` to track cache effectiveness
3. **Adjust TTL**: Increase TTL for stable token configurations
4. **Prune Regularly**: Call `pruneAllCaches()` periodically in long-running applications
5. **Clear on Config Changes**: Call `clearAllCaches()` when theme configuration changes

## Troubleshooting

### Low Hit Rate

If cache hit rate is low (<50%):
- Check if token parameters are changing frequently
- Consider increasing cache size
- Verify TTL is appropriate for your use case

### Memory Issues

If memory usage is high:
- Reduce `maxSize` for each cache
- Decrease TTL to expire entries sooner
- Call `pruneAllCaches()` more frequently

### Stale Results

If cached results seem outdated:
- Reduce TTL
- Call `clearAllCaches()` when configuration changes
- Disable caching during development with `cache.setEnabled(false)`

## Future Enhancements

Potential improvements for future versions:
- Persistent caching (localStorage/IndexedDB)
- Cache warming strategies
- Compression for large cache entries
- Cache invalidation patterns
- Distributed caching support
